version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: knowledge_assistant_db
    environment:
      POSTGRES_DB: knowledge_assistant
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init_db.sql:/docker-entrypoint-initdb.d/init_db.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - knowledge_assistant_network

  # FastAPI Backend
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    container_name: knowledge_assistant_backend
    environment:
      - DATABASE_URL=postgresql://postgres:postgres123@postgres:5432/knowledge_assistant
      - SECRET_KEY=${SECRET_KEY}
      - DEBUG=false
      - CHROMA_PERSIST_DIRECTORY=/app/data/chroma_db
      
      # LLM Configuration (Open Source)
      - LLM_TYPE=${LLM_TYPE:-huggingface}
      - LLM_MODEL_NAME=${LLM_MODEL_NAME:-microsoft/DialoGPT-medium}
      - LLM_DEVICE=${LLM_DEVICE:-cpu}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.7}
      - LLM_MAX_LENGTH=${LLM_MAX_LENGTH:-512}
      - LLM_USE_QUANTIZATION=${LLM_USE_QUANTIZATION:-false}
      
      # Embedding Configuration (Open Source)
      - EMBEDDING_MODEL_TYPE=${EMBEDDING_MODEL_TYPE:-sentence-transformers}
      - EMBEDDING_MODEL_NAME=${EMBEDDING_MODEL_NAME:-all-MiniLM-L6-v2}
      - EMBEDDING_DEVICE=${EMBEDDING_DEVICE:-cpu}
      - EMBEDDING_BATCH_SIZE=${EMBEDDING_BATCH_SIZE:-32}
      
      # Web Search Configuration (Open Source)
      - WEB_SEARCH_ENGINE=${WEB_SEARCH_ENGINE:-duckduckgo}
      - WEB_SEARCH_MAX_RESULTS=${WEB_SEARCH_MAX_RESULTS:-5}
      - WEB_SEARCH_TIMEOUT=${WEB_SEARCH_TIMEOUT:-10}
      
      # Monitoring Configuration (Open Source)
      - ENABLE_MONITORING=${ENABLE_MONITORING:-true}
      - MONITORING_DB_PATH=/app/data/monitoring.db
      - PROMETHEUS_METRICS_ENABLED=${PROMETHEUS_METRICS_ENABLED:-true}
      
      # Optional: Azure Key Vault (if needed)
      - AZURE_CLIENT_ID=${AZURE_CLIENT_ID:-}
      - AZURE_CLIENT_SECRET=${AZURE_CLIENT_SECRET:-}
      - AZURE_TENANT_ID=${AZURE_TENANT_ID:-}
      - KEY_VAULT_URL=${KEY_VAULT_URL:-}
      
      # Optional: OpenAI (if you want to use GPT models)
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./backend/app:/app/app
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - knowledge_assistant_network
    restart: unless-stopped

  # Streamlit Frontend
  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
    container_name: knowledge_assistant_frontend
    environment:
      - STREAMLIT_SERVER_PORT=8501
      - STREAMLIT_SERVER_ADDRESS=0.0.0.0
    ports:
      - "8501:8501"
    depends_on:
      backend:
        condition: service_healthy
    volumes:
      - ./frontend:/app
    networks:
      - knowledge_assistant_network
    restart: unless-stopped

  # Redis for caching (optional)
  redis:
    image: redis:7-alpine
    container_name: knowledge_assistant_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - knowledge_assistant_network
    restart: unless-stopped

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: knowledge_assistant_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx.conf:/etc/nginx/nginx.conf
      - ./config/ssl:/etc/nginx/ssl
    depends_on:
      - backend
      - frontend
    networks:
      - knowledge_assistant_network
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:

networks:
  knowledge_assistant_network:
    driver: bridge